{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extração e Engenharia de Features\n",
    "\n",
    "## Objetivo\n",
    "Transformar dados genômicos brutos em features numéricas utilizáveis por algoritmos de ML, normalizando para o formato TPM compatível com a matriz de treinamento.\n",
    "\n",
    "## Passos do Pipeline\n",
    "1. Extração de Features Básicas (TPM dos organismos)\n",
    "2. Engenharia de Features Avançadas (diversidade, razões, mutações)\n",
    "3. Normalização e Transformação\n",
    "4. Alinhamento com Matriz de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/larissa/Desktop/TCC_metatrascriptomica\n",
      "Scripts directory: /Users/larissa/Desktop/TCC_metatrascriptomica/scripts ✅\n",
      "Diretório de trabalho: /Users/larissa/Desktop/TCC_metatrascriptomica/notebooks\n"
     ]
    }
   ],
   "source": [
    "# Configuração inicial\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Obter diretório raiz do projeto\n",
    "notebook_dir = Path().resolve()\n",
    "if 'notebooks' in str(notebook_dir):\n",
    "    project_root = notebook_dir.parent\n",
    "else:\n",
    "    project_root = Path('/Users/larissa/Desktop/TCC_metatrascriptomica')\n",
    "\n",
    "# Adicionar scripts ao path\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "# Verificar se scripts existe\n",
    "scripts_dir = project_root / \"scripts\"\n",
    "if not scripts_dir.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Diretório 'scripts' não encontrado em {project_root}.\\n\"\n",
    "        f\"Diretório atual de trabalho: {Path().resolve()}\\n\"\n",
    "        f\"Tente executar: os.chdir('{project_root / 'notebooks'}')\"\n",
    "    )\n",
    "\n",
    "# Configurar caminhos relativos\n",
    "DATA_DIR = project_root / \"data\"\n",
    "RESULTS_DIR = project_root / \"results\"\n",
    "FEATURES_DIR = RESULTS_DIR / \"features\"\n",
    "\n",
    "FEATURES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Mudar para diretório do notebook (opcional, mas útil)\n",
    "os.chdir(project_root / \"notebooks\")\n",
    "\n",
    "print(f\"Project root: {project_root}\")\n",
    "print(f\"Scripts directory: {scripts_dir} {'✅' if scripts_dir.exists() else '❌'}\")\n",
    "print(f\"Diretório de trabalho: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Extração de Features Básicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraindo features TPM...\n",
      "  Usando relatório Kraken2\n",
      "✅ Total de organismos com TPM: 50\n"
     ]
    }
   ],
   "source": [
    "from scripts.feature_extraction import extract_tpm_from_kraken2, extract_tpm_from_bracken\n",
    "from scripts.feature_engineering import (\n",
    "    calculate_shannon_index,\n",
    "    calculate_virus_bacteria_ratio,\n",
    "    detect_key_pathogens\n",
    ")\n",
    "\n",
    "# Caminhos dos relatórios\n",
    "kraken_report = str(RESULTS_DIR / \"kraken2_reports\" / \"patient_joao_kraken2_report.txt\")\n",
    "bracken_report = str(RESULTS_DIR / \"kraken2_reports\" / \"patient_joao_bracken_output.txt\")\n",
    "\n",
    "# Extrair TPM (usar Bracken se disponível, senão Kraken2)\n",
    "print(\"Extraindo features TPM...\")\n",
    "if os.path.exists(bracken_report):\n",
    "    print(\"  Usando relatório Bracken (mais preciso)\")\n",
    "    tpm_dict = extract_tpm_from_bracken(bracken_report)\n",
    "elif os.path.exists(kraken_report):\n",
    "    print(\"  Usando relatório Kraken2\")\n",
    "    tpm_dict = extract_tpm_from_kraken2(kraken_report)\n",
    "else:\n",
    "    print(\"❌ Nenhum relatório encontrado. Execute o Notebook 1 primeiro.\")\n",
    "    tpm_dict = {}\n",
    "\n",
    "print(f\"✅ Total de organismos com TPM: {len(tpm_dict)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Engenharia de Features Avançadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculando features avançadas...\n",
      "  ✅ Shannon Index: 0.2958\n",
      "  ✅ Razão Vírus/Bactérias: 74882.5217\n",
      "  ✅ Patógenos detectados: 1\n",
      "  ✅ Features de variantes extraídas\n",
      "  ⚠️ Arquivo de cobertura não encontrado: /Users/larissa/Desktop/TCC_metatrascriptomica/results/variants/patient_joao_coverage.txt\n",
      "\n",
      "✅ Features avançadas compiladas: 10 features\n"
     ]
    }
   ],
   "source": [
    "from scripts.feature_extraction import extract_variant_features, extract_coverage_stats\n",
    "\n",
    "# Calcular features avançadas\n",
    "print(\"\\nCalculando features avançadas...\")\n",
    "if tpm_dict and len(tpm_dict) > 0:\n",
    "    shannon_idx = calculate_shannon_index(tpm_dict)\n",
    "    print(f\"  ✅ Shannon Index: {shannon_idx:.4f}\")\n",
    "else:\n",
    "    shannon_idx = 0.0\n",
    "\n",
    "if os.path.exists(kraken_report):\n",
    "    vbr_ratio = calculate_virus_bacteria_ratio(kraken_report)\n",
    "    print(f\"  ✅ Razão Vírus/Bactérias: {vbr_ratio:.4f}\")\n",
    "    pathogens = detect_key_pathogens(kraken_report)\n",
    "    print(f\"  ✅ Patógenos detectados: {sum(pathogens.values())}\")\n",
    "else:\n",
    "    vbr_ratio = 0.0\n",
    "    pathogens = {}\n",
    "\n",
    "# Features de variantes\n",
    "variants_table = str(RESULTS_DIR / \"variants\" / \"patient_joao_variants_table.csv\")\n",
    "if os.path.exists(variants_table):\n",
    "    variant_features = extract_variant_features(variants_table)\n",
    "    print(f\"  ✅ Features de variantes extraídas\")\n",
    "else:\n",
    "    variant_features = {'total_variants': 0, 'spike_mutations': 0, 'non_synonymous': 0, 'high_impact': 0}\n",
    "    print(f\"  ⚠️ Tabela de variantes não encontrada: {variants_table}\")\n",
    "\n",
    "# Features de cobertura\n",
    "coverage_file = str(RESULTS_DIR / \"variants\" / \"patient_joao_coverage.txt\")\n",
    "if os.path.exists(coverage_file):\n",
    "    coverage_stats = extract_coverage_stats(coverage_file)\n",
    "    print(f\"  ✅ Estatísticas de cobertura extraídas\")\n",
    "else:\n",
    "    coverage_stats = {'mean_depth': 0, 'median_depth': 0}\n",
    "    print(f\"  ⚠️ Arquivo de cobertura não encontrado: {coverage_file}\")\n",
    "\n",
    "# Compilar features avançadas\n",
    "advanced_features = {\n",
    "    'shannon_index': shannon_idx,\n",
    "    'virus_bacteria_ratio': vbr_ratio,\n",
    "    'spike_mutations': variant_features.get('spike_mutations', 0),\n",
    "    'viral_load': coverage_stats.get('mean_depth', 0),\n",
    "    **pathogens\n",
    "}\n",
    "\n",
    "print(f\"\\n✅ Features avançadas compiladas: {len(advanced_features)} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Normalização e Alinhamento com Matriz de Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando matriz de treinamento...\n",
      "  ✅ Matriz carregada: 100 amostras, 4671 colunas\n",
      "  ✅ Colunas de features: 4671\n",
      "\n",
      "Criando vetor de features alinhado...\n",
      "  ✅ Vetor criado: 4678 features\n",
      "Aplicando transformação logarítmica...\n",
      "  ✅ Transformação log aplicada\n",
      "\n",
      "✅ Vetores de features salvos:\n",
      "  - /Users/larissa/Desktop/TCC_metatrascriptomica/results/features/patient_joao_features_vector.csv\n",
      "  - /Users/larissa/Desktop/TCC_metatrascriptomica/results/features/patient_joao_features_vector_log.csv\n"
     ]
    }
   ],
   "source": [
    "from scripts.feature_engineering import create_feature_vector, apply_log_transform\n",
    "\n",
    "# Carregar matriz de treinamento para obter colunas\n",
    "training_matrix_path = str(DATA_DIR / \"training\" / \"pivoted-virome-organisms-atleast10tpm-species-covid-TCC-pos-2.csv\")\n",
    "\n",
    "if os.path.exists(training_matrix_path):\n",
    "    print(\"Carregando matriz de treinamento...\")\n",
    "    train_matrix = pd.read_csv(training_matrix_path)\n",
    "    print(f\"  ✅ Matriz carregada: {train_matrix.shape[0]} amostras, {train_matrix.shape[1]} colunas\")\n",
    "\n",
    "    # Obter colunas de features (excluir colunas não-feature)\n",
    "    feature_columns = [col for col in train_matrix.columns if col not in ['sample_id', 'covid_status']]\n",
    "    print(f\"  ✅ Colunas de features: {len(feature_columns)}\")\n",
    "\n",
    "    # Criar vetor de features alinhado\n",
    "    print(\"\\nCriando vetor de features alinhado...\")\n",
    "    patient_features = create_feature_vector(\n",
    "        tpm_dict=tpm_dict,\n",
    "        training_columns=feature_columns,\n",
    "        advanced_features=advanced_features\n",
    "    )\n",
    "    print(f\"  ✅ Vetor criado: {patient_features.shape[1]} features\")\n",
    "\n",
    "    # Aplicar transformação logarítmica\n",
    "    print(\"Aplicando transformação logarítmica...\")\n",
    "    patient_features_log = apply_log_transform(patient_features)\n",
    "    print(\"  ✅ Transformação log aplicada\")\n",
    "\n",
    "    # Salvar vetores\n",
    "    features_file = str(FEATURES_DIR / \"patient_joao_features_vector.csv\")\n",
    "    features_log_file = str(FEATURES_DIR / \"patient_joao_features_vector_log.csv\")\n",
    "    \n",
    "    patient_features.to_csv(features_file, index=False)\n",
    "    patient_features_log.to_csv(features_log_file, index=False)\n",
    "    \n",
    "    print(f\"\\n✅ Vetores de features salvos:\")\n",
    "    print(f\"  - {features_file}\")\n",
    "    print(f\"  - {features_log_file}\")\n",
    "else:\n",
    "    print(f\"❌ Matriz de treinamento não encontrada: {training_matrix_path}\")\n",
    "    print(\"   O vetor de features não pode ser criado sem a matriz de treinamento.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCC Metatranscriptomica",
   "language": "python",
   "name": "tcc-metatranscriptomica"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
