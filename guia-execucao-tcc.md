# Guia de Execu√ß√£o Passo a Passo - TCC Metatranscript√¥mica & Machine Learning

## √çndice
1. [Vis√£o Geral](#vis√£o-geral)
2. [Etapa 1: Pipeline de Metatranscript√¥mica (Viroma)](#etapa-1-pipeline-de-metatranscript√¥mica-viroma)
3. [Etapa 2: Pipeline de Chamada de Variantes do SARS-CoV-2](#etapa-2-pipeline-de-chamada-de-variantes-do-sars-cov-2)
4. [Etapa 3: Extra√ß√£o e Engenharia de Features](#etapa-3-extra√ß√£o-e-engenharia-de-features)
5. [Etapa 4: Treinamento e Predi√ß√£o com Machine Learning](#etapa-4-treinamento-e-predi√ß√£o-com-machine-learning)
6. [Recursos e Refer√™ncias](#recursos-e-refer√™ncias)

---

## Vis√£o Geral

Este guia detalha a execu√ß√£o completa do TCC, dividido em 4 entregas principais:
- **Entrega 1**: Pipeline de metatranscript√¥mica (viroma)
- **Entrega 2**: Pipeline de chamada de variantes do SARS-CoV-2
- **Entrega 3**: Pipeline de extra√ß√£o e engenharia de features
- **Entrega 4**: Treinamento e predi√ß√£o com Machine Learning

---

## Etapa 1: Pipeline de Metatranscript√¥mica (Viroma)

### Objetivo
Processar os arquivos FASTQ brutos da amostra do paciente para identificar organismos presentes (principalmente v√≠rus), confirmar a presen√ßa de SARS-CoV-2 e avaliar coinfec√ß√µes.

### Dados de Entrada

**Arquivos FASTQ do Paciente Jo√£o:**
- `patient_joao_VIROMA_S21_R1_001.fastq.gz` (Reads forward)
- `patient_joao_VIROMA_S21_R2_001.fastq.gz` (Reads reverse)

**Links de Download:**
```
https://aulas-pos-hiae-public-data.s3.sa-east-1.amazonaws.com/TCC-metagenomica/patient_joao_VIROMA_S21_R1_001.fastq.gz
https://aulas-pos-hiae-public-data.s3.sa-east-1.amazonaws.com/TCC-metagenomica/patient_joao_VIROMA_S21_R2_001.fastq.gz
```

**Banco de Dados Necess√°rios:**
- Genoma humano de refer√™ncia (HG38) - para remo√ß√£o de reads do hospedeiro
- Banco de dados Kraken2 (v√≠rus/bact√©rias) - para classifica√ß√£o taxon√¥mica

### Passo a Passo Detalhado

#### 1.1 Controle de Qualidade (QC)

**Ferramenta: FastQC**

**Instala√ß√£o:**
```bash
# Via conda
conda install -c bioconda fastqc

# Ou via apt (Linux)
sudo apt-get install fastqc
```

**Como Utilizar:**
```bash
# An√°lise de qualidade para cada arquivo
fastqc patient_joao_VIROMA_S21_R1_001.fastq.gz -o qc_reports/
fastqc patient_joao_VIROMA_S21_R2_001.fastq.gz -o qc_reports/
```

**Sa√≠da Esperada:**
- Arquivos HTML com relat√≥rios de qualidade
- M√©tricas: Phred scores, conte√∫do GC, comprimento de reads, presen√ßa de adaptadores

**Ferramenta: MultiQC** (para consolidar relat√≥rios)

**Instala√ß√£o:**
```bash
conda install -c bioconda multiqc
```

**Como Utilizar:**
```bash
multiqc qc_reports/ -o multiqc_report/
```

**Sa√≠da Esperada:**
- Relat√≥rio HTML consolidado com todas as m√©tricas de qualidade

---

#### 1.2 Pr√©-processamento (Trimming)

**Ferramenta: Trimmomatic**

**Instala√ß√£o:**
```bash
conda install -c bioconda trimmomatic
```

**Como Utilizar:**
```bash
trimmomatic PE \
  patient_joao_VIROMA_S21_R1_001.fastq.gz \
  patient_joao_VIROMA_S21_R2_001.fastq.gz \
  patient_joao_R1_paired.fastq.gz \
  patient_joao_R1_unpaired.fastq.gz \
  patient_joao_R2_paired.fastq.gz \
  patient_joao_R2_unpaired.fastq.gz \
  ILLUMINACLIP:TruSeq3-PE.fa:2:30:10 \
  LEADING:3 \
  TRAILING:3 \
  SLIDINGWINDOW:4:15 \
  MINLEN:36
```

**Par√¢metros:**
- `ILLUMINACLIP`: Remove adaptadores Illumina
- `LEADING:3`: Remove bases com qualidade < 3 no in√≠cio
- `TRAILING:3`: Remove bases com qualidade < 3 no final
- `SLIDINGWINDOW:4:15`: Janela deslizante de 4 bases, m√©dia de qualidade m√≠nima 15
- `MINLEN:36`: Remove reads com menos de 36 bases

**Alternativa: fastp** (mais r√°pido)

**Instala√ß√£o:**
```bash
conda install -c bioconda fastp
```

**Como Utilizar:**
```bash
fastp \
  -i patient_joao_VIROMA_S21_R1_001.fastq.gz \
  -I patient_joao_VIROMA_S21_R2_001.fastq.gz \
  -o patient_joao_R1_trimmed.fastq.gz \
  -O patient_joao_R2_trimmed.fastq.gz \
  --detect_adapter_for_pe \
  --cut_front \
  --cut_tail \
  --trim_poly_g \
  --length_required 36
```

**Sa√≠da Esperada:**
- Arquivos FASTQ limpos (paired e unpaired)
- Relat√≥rio HTML com estat√≠sticas de trimming

---

#### 1.3 Remo√ß√£o de Reads do Hospedeiro (Humano)

**Ferramenta: Bowtie2**

**Instala√ß√£o:**
```bash
conda install -c bioconda bowtie2
```

**Onde Obter o Genoma de Refer√™ncia Humano (HG38):**
```bash
# Download do genoma humano
wget https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/hg38.fa.gz
gunzip hg38.fa.gz

# Ou usar vers√£o j√° indexada
# https://genome-idx.s3.amazonaws.com/bt/GRCh38_no_alt_analysis_set_GCA_000001405.15.fasta.tar.gz
```

**Como Utilizar:**
```bash
# 1. Indexar o genoma humano
bowtie2-build hg38.fa hg38_index

# 2. Alinhar e manter apenas reads n√£o-alinhadas
bowtie2 -x hg38_index \
  -1 patient_joao_R1_paired.fastq.gz \
  -2 patient_joao_R2_paired.fastq.gz \
  --un-conc patient_joao_nonhuman_R%.fastq.gz \
  -S patient_joao_aligned_human.sam \
  --threads 8

# 3. Converter SAM para BAM (opcional, para inspe√ß√£o)
samtools view -bS patient_joao_aligned_human.sam > patient_joao_aligned_human.bam
```

**Sa√≠da Esperada:**
- `patient_joao_nonhuman_R1.fastq.gz` e `patient_joao_nonhuman_R2.fastq.gz` (reads n√£o-humanas)

---

#### 1.4 Classifica√ß√£o Taxon√¥mica

**Ferramenta: Kraken2**

**Instala√ß√£o:**
```bash
conda install -c bioconda kraken2
```

**Onde Obter o Banco de Dados Kraken2:**

**Op√ß√£o 1: Banco de V√≠rus (mais r√°pido, menor)**
```bash
# Download do banco de v√≠rus
kraken2-build --download-library viral --db viral_db
kraken2-build --build --db viral_db
```

**Op√ß√£o 2: Banco Completo (v√≠rus + bact√©rias + archaea)**
```bash
# Download completo (requer ~100GB de espa√ßo)
kraken2-build --download-library viral --db full_db
kraken2-build --download-library bacteria --db full_db
kraken2-build --download-library archaea --db full_db
kraken2-build --build --db full_db
```

**Op√ß√£o 3: Usar banco pr√©-constru√≠do (recomendado para Colab)**
```bash
# Links para bancos pr√©-constru√≠dos:
# https://genome-idx.s3.amazonaws.com/kraken/k2_pluspf_20221209.tar.gz (v√≠rus + bact√©rias)
# https://genome-idx.s3.amazonaws.com/kraken/k2_viral_20221209.tar.gz (apenas v√≠rus)
```

**Como Utilizar:**
```bash
kraken2 \
  --db viral_db \
  --paired \
  --threads 8 \
  --output patient_joao_kraken2_output.txt \
  --report patient_joao_kraken2_report.txt \
  patient_joao_nonhuman_R1.fastq.gz \
  patient_joao_nonhuman_R2.fastq.gz
```

**Sa√≠da Esperada:**
- `patient_joao_kraken2_output.txt`: Classifica√ß√£o de cada read
- `patient_joao_kraken2_report.txt`: Relat√≥rio agregado por t√°xon (abund√¢ncia)

**Ferramenta: Bracken** (para estimar abund√¢ncia mais precisa)

**Instala√ß√£o:**
```bash
conda install -c bioconda bracken
```

**Como Utilizar:**
```bash
# 1. Construir banco Bracken a partir do banco Kraken2
bracken-build -d viral_db -t 8 -k 35 -l 100

# 2. Estimar abund√¢ncia
bracken \
  -d viral_db \
  -i patient_joao_kraken2_report.txt \
  -o patient_joao_bracken_output.txt \
  -r 100 \
  -l S
```

**Sa√≠da Esperada:**
- `patient_joao_bracken_output.txt`: Abund√¢ncia estimada por esp√©cie

---

#### 1.5 Visualiza√ß√£o

**Ferramenta: Krona** (visualiza√ß√£o interativa)

**Instala√ß√£o:**
```bash
conda install -c bioconda krona
```

**Como Utilizar:**
```bash
# Converter relat√≥rio Kraken2 para formato Krona
ktImportTaxonomy patient_joao_kraken2_report.txt -o patient_joao_krona.html
```

**Sa√≠da Esperada:**
- Arquivo HTML interativo com visualiza√ß√£o hier√°rquica da composi√ß√£o taxon√¥mica

**Alternativa: Python (matplotlib/seaborn)**
```python
import pandas as pd
import matplotlib.pyplot as plt

# Ler relat√≥rio Kraken2
df = pd.read_csv('patient_joao_kraken2_report.txt', sep='\t', 
                 names=['percent', 'reads', 'tax_reads', 'rank', 'taxid', 'name'])

# Filtrar top organismos
top_orgs = df[df['rank'] == 'S'].nlargest(10, 'reads')

# Gr√°fico de barras
plt.figure(figsize=(10, 6))
plt.barh(top_orgs['name'], top_orgs['reads'])
plt.xlabel('N√∫mero de Reads')
plt.title('Top 10 Organismos Detectados')
plt.tight_layout()
plt.savefig('top_organisms.png')
```

---

### Sa√≠das Finais da Etapa 1

1. **Relat√≥rios de Qualidade:**
   - Relat√≥rio MultiQC consolidado
   - Estat√≠sticas de trimming

2. **Dados Processados:**
   - Arquivos FASTQ limpos e sem reads humanas
   - Relat√≥rio Kraken2 com classifica√ß√£o taxon√¥mica
   - Relat√≥rio Bracken com abund√¢ncia estimada

3. **Visualiza√ß√µes:**
   - Gr√°fico Krona interativo
   - Gr√°ficos de barras dos top organismos

4. **Interpreta√ß√£o:**
   - Confirma√ß√£o da presen√ßa de SARS-CoV-2
   - Lista de coinfec√ß√µes detectadas
   - Abund√¢ncia relativa de cada organismo

---

## Etapa 2: Pipeline de Chamada de Variantes do SARS-CoV-2

### Objetivo
Reconstruir o genoma viral presente na amostra e identificar muta√ß√µes em rela√ß√£o ao genoma de refer√™ncia, determinando a linhagem.

### Dados de Entrada

**Arquivos FASTQ Processados:**
- `patient_joao_nonhuman_R1.fastq.gz`
- `patient_joao_nonhuman_R2.fastq.gz`

**Genoma de Refer√™ncia SARS-CoV-2:**
- Genoma Wuhan (NC_045512.2)

**Onde Obter:**
```bash
# Download direto do NCBI
wget https://www.ncbi.nlm.nih.gov/sviewer/viewer.cgi?tool=portal&save=file&log$=seqview&db=nuccore&report=fasta&id=1798174254 -O NC_045512.2.fasta

# Ou via efetch
efetch -db nuccore -id NC_045512.2 -format fasta > NC_045512.2.fasta
```

---

### Passo a Passo Detalhado

#### 2.1 Alinhamento ao Genoma de Refer√™ncia

**Ferramenta: BWA-MEM**

**Instala√ß√£o:**
```bash
conda install -c bioconda bwa
```

**Como Utilizar:**
```bash
# 1. Indexar o genoma de refer√™ncia
bwa index NC_045512.2.fasta

# 2. Alinhar reads ao genoma de refer√™ncia
bwa mem -t 8 \
  NC_045512.2.fasta \
  patient_joao_nonhuman_R1.fastq.gz \
  patient_joao_nonhuman_R2.fastq.gz \
  > patient_joao_aligned.sam
```

**Alternativa: Bowtie2**
```bash
# 1. Indexar
bowtie2-build NC_045512.2.fasta sars_cov2_index

# 2. Alinhar
bowtie2 -x sars_cov2_index \
  -1 patient_joao_nonhuman_R1.fastq.gz \
  -2 patient_joao_nonhuman_R2.fastq.gz \
  -S patient_joao_aligned.sam \
  --threads 8
```

**Sa√≠da Esperada:**
- Arquivo SAM com alinhamentos

---

#### 2.2 Processamento do BAM

**Ferramenta: samtools**

**Instala√ß√£o:**
```bash
conda install -c bioconda samtools
```

**Como Utilizar:**
```bash
# 1. Converter SAM para BAM
samtools view -bS patient_joao_aligned.sam > patient_joao_aligned.bam

# 2. Ordenar por coordenada
samtools sort patient_joao_aligned.bam -o patient_joao_sorted.bam

# 3. Indexar
samtools index patient_joao_sorted.bam

# 4. Estat√≠sticas de cobertura
samtools depth patient_joao_sorted.bam > patient_joao_coverage.txt
samtools stats patient_joao_sorted.bam > patient_joao_stats.txt
```

**Ferramenta: Picard** (remo√ß√£o de duplicatas)

**Instala√ß√£o:**
```bash
conda install -c bioconda picard
```

**Como Utilizar:**
```bash
picard MarkDuplicates \
  I=patient_joao_sorted.bam \
  O=patient_joao_dedup.bam \
  M=patient_joao_duplicates_metrics.txt \
  REMOVE_DUPLICATES=true

# Re-indexar ap√≥s remo√ß√£o de duplicatas
samtools index patient_joao_dedup.bam
```

**Sa√≠da Esperada:**
- BAM ordenado e indexado
- Estat√≠sticas de cobertura e profundidade
- BAM sem duplicatas

---

#### 2.3 Chamada de Variantes

**Op√ß√£o 1: BCFtools**

**Instala√ß√£o:**
```bash
conda install -c bioconda bcftools
```

**Como Utilizar:**
```bash
# 1. Indexar genoma de refer√™ncia (se ainda n√£o feito)
samtools faidx NC_045512.2.fasta

# 2. Chamada de variantes
bcftools mpileup -f NC_045512.2.fasta \
  patient_joao_dedup.bam \
  | bcftools call -mv -Oz -o patient_joao_variants.vcf.gz

# 3. Indexar VCF
bcftools index patient_joao_variants.vcf.gz

# 4. Visualizar variantes
bcftools view patient_joao_variants.vcf.gz | less
```

**Op√ß√£o 2: FreeBayes**

**Instala√ß√£o:**
```bash
conda install -c bioconda freebayes
```

**Como Utilizar:**
```bash
freebayes \
  -f NC_045512.2.fasta \
  -b patient_joao_dedup.bam \
  > patient_joao_variants_freebayes.vcf
```

**Op√ß√£o 3: LoFreq** (especializado em baixa frequ√™ncia)

**Instala√ß√£o:**
```bash
conda install -c bioconda lofreq
```

**Como Utilizar:**
```bash
# 1. Calibrar alinhamento
lofreq viterbi -f NC_045512.2.fasta patient_joao_dedup.bam | \
  samtools sort - > patient_joao_calibrated.bam
samtools index patient_joao_calibrated.bam

# 2. Chamada de variantes
lofreq call-parallel \
  --pp-threads 8 \
  -f NC_045512.2.fasta \
  -o patient_joao_variants_lofreq.vcf \
  patient_joao_calibrated.bam
```

**Sa√≠da Esperada:**
- Arquivo VCF com variantes identificadas (SNPs e indels)

---

#### 2.4 Anota√ß√£o de Variantes

**Ferramenta: SnpEff**

**Instala√ß√£o:**
```bash
conda install -c bioconda snpeff
```

**Como Obter Banco de Dados SARS-CoV-2 para SnpEff:**
```bash
# Download do banco de dados SARS-CoV-2
# O SnpEff j√° vem com alguns bancos, mas pode ser necess√°rio adicionar o SARS-CoV-2
# Verificar: snpeff databases | grep -i sars
```

**Como Utilizar:**
```bash
# Anotar variantes
snpEff \
  -v sarsCov2 \
  patient_joao_variants.vcf.gz \
  > patient_joao_variants_annotated.vcf
```

**Sa√≠da Esperada:**
- VCF anotado com impacto funcional das muta√ß√µes (sin√¥nima, n√£o-sin√¥nima, etc.)

**Processamento do VCF Anotado:**
```python
import pandas as pd
import vcf

# Ler VCF anotado
vcf_reader = vcf.Reader(open('patient_joao_variants_annotated.vcf', 'r'))

variants = []
for record in vcf_reader:
    variant = {
        'CHROM': record.CHROM,
        'POS': record.POS,
        'REF': record.REF,
        'ALT': str(record.ALT[0]),
        'QUAL': record.QUAL,
        'DP': record.INFO.get('DP', 0),
        'AF': record.INFO.get('AF', [0])[0] if record.INFO.get('AF') else 0
    }
    # Extrair anota√ß√µes do SnpEff
    if 'ANN' in record.INFO:
        ann = record.INFO['ANN'][0].split('|')
        variant['GENE'] = ann[3]
        variant['EFFECT'] = ann[1]
        variant['IMPACT'] = ann[2]
    variants.append(variant)

df_variants = pd.DataFrame(variants)
df_variants.to_csv('patient_joao_variants_table.csv', index=False)
```

---

#### 2.5 Determina√ß√£o de Linhagem

**Ferramenta: Pangolin**

**Instala√ß√£o:**
```bash
# Via pip
pip install pangolin

# Ou via conda
conda install -c bioconda pangolin
```

**Como Utilizar:**
```bash
# Op√ß√£o 1: Usar VCF
pangolin patient_joao_variants.vcf.gz --outfile patient_joao_lineage.csv

# Op√ß√£o 2: Usar BAM (recomendado - mais preciso)
pangolin patient_joao_dedup.bam --outfile patient_joao_lineage.csv

# Op√ß√£o 3: Usar FASTA (se tiver genoma consenso)
# Primeiro, gerar genoma consenso
samtools consensus -f fasta patient_joao_dedup.bam > patient_joao_consensus.fasta
pangolin patient_joao_consensus.fasta --outfile patient_joao_lineage.csv
```

**Sa√≠da Esperada:**
- CSV com linhagem identificada (ex: B.1.617.2 - Delta, BA.1 - √îmicron)
- Probabilidade e qualidade da classifica√ß√£o

**Web Interface (Alternativa):**
- https://pangolin.cog-uk.io/
- Upload do arquivo VCF ou FASTA consenso

---

### Sa√≠das Finais da Etapa 2

1. **Arquivos de Alinhamento:**
   - BAM ordenado, indexado e sem duplicatas
   - Estat√≠sticas de cobertura

2. **Variantes:**
   - Arquivo VCF com variantes identificadas
   - VCF anotado com impacto funcional

3. **Tabela de Variantes Anotadas:**
   - CSV com colunas: Posi√ß√£o, Gene, Muta√ß√£o, Tipo, Impacto, Frequ√™ncia

4. **Linhagem:**
   - Relat√≥rio Pangolin com linhagem identificada

5. **Interpreta√ß√£o:**
   - Muta√ß√µes de interesse cl√≠nico (ex: N501Y, E484K, D614G)
   - Associa√ß√£o com variantes de preocupa√ß√£o (VOCs)

---

## Etapa 3: Extra√ß√£o e Engenharia de Features

### Objetivo
Transformar dados gen√¥micos brutos em features num√©ricas utiliz√°veis por algoritmos de ML, normalizando para o formato TPM compat√≠vel com a matriz de treinamento.

### Dados de Entrada

**Dados do Paciente Jo√£o:**
- Relat√≥rio Kraken2: `patient_joao_kraken2_report.txt`
- Relat√≥rio Bracken: `patient_joao_bracken_output.txt`
- Variantes identificadas: `patient_joao_variants_table.csv`
- Estat√≠sticas de cobertura: `patient_joao_coverage.txt`

**Matriz de Treinamento:**
- `pivoted-virome-organisms-atleast10tpm-species-covid-TCC-pos.csv`

**Onde Obter:**
- Fornecido pelo professor (download do arquivo CSV)

---

### Passo a Passo Detalhado

#### 3.1 Extra√ß√£o de Features B√°sicas

**Processamento do Relat√≥rio Kraken2/Bracken:**

```python
import pandas as pd
import numpy as np

# Ler relat√≥rio Kraken2
kraken_report = pd.read_csv('patient_joao_kraken2_report.txt', sep='\t',
                           names=['percent', 'reads', 'tax_reads', 'rank', 'taxid', 'name'])

# Filtrar apenas esp√©cies (rank == 'S')
species = kraken_report[kraken_report['rank'] == 'S'].copy()

# Calcular TPM (Transcripts Per Million)
total_reads = species['reads'].sum()
species['TPM'] = (species['reads'] / total_reads) * 1_000_000

# Criar dicion√°rio de features (nome da esp√©cie -> TPM)
features_dict = dict(zip(species['name'], species['TPM']))
```

**Alternativa usando Bracken (mais preciso):**
```python
# Ler relat√≥rio Bracken
bracken_report = pd.read_csv('patient_joao_bracken_output.txt', sep='\t')

# Bracken j√° fornece abund√¢ncia estimada
features_dict = dict(zip(bracken_report['name'], bracken_report['new_est_reads']))
```

---

#### 3.2 Engenharia de Features Avan√ßadas

**Features Adicionais que Podem ser Extra√≠das:**

```python
# 1. Diversidade Alfa (Shannon Index)
from scipy.stats import entropy

# Calcular Shannon Index
proportions = species['reads'] / species['reads'].sum()
shannon_index = entropy(proportions, base=2)

# 2. Raz√£o V√≠rus/Bact√©rias
virus_reads = kraken_report[kraken_report['name'].str.contains('virus', case=False, na=False)]['reads'].sum()
bacteria_reads = kraken_report[kraken_report['rank'] == 'S']['reads'].sum() - virus_reads
virus_bacteria_ratio = virus_reads / bacteria_reads if bacteria_reads > 0 else 0

# 3. Presen√ßa/Aus√™ncia de Pat√≥genos-Chave
key_pathogens = {
    'SARS-CoV-2': 'Severe acute respiratory syndrome coronavirus 2' in species['name'].values,
    'Influenza': 'Influenza' in ' '.join(species['name'].values),
    'RSV': 'Respiratory syncytial' in ' '.join(species['name'].values),
    'Streptococcus pneumoniae': 'Streptococcus pneumoniae' in species['name'].values
}

# 4. N√∫mero de Muta√ß√µes no Gene Spike
variants_df = pd.read_csv('patient_joao_variants_table.csv')
spike_mutations = variants_df[variants_df['GENE'] == 'S'].shape[0]

# 5. Carga Viral Estimada (cobertura m√©dia do SARS-CoV-2)
coverage_df = pd.read_csv('patient_joao_coverage.txt', sep='\t', names=['chr', 'pos', 'depth'])
viral_load = coverage_df['depth'].mean()

# 6. N√∫mero Total de Organismos Detectados
total_organisms = species.shape[0]

# 7. Abund√¢ncia Relativa do SARS-CoV-2
sars_cov2_tpm = features_dict.get('Severe acute respiratory syndrome coronavirus 2', 0)

# Compilar todas as features
advanced_features = {
    'shannon_index': shannon_index,
    'virus_bacteria_ratio': virus_bacteria_ratio,
    'spike_mutations': spike_mutations,
    'viral_load': viral_load,
    'total_organisms': total_organisms,
    'sars_cov2_abundance': sars_cov2_tpm,
    **key_pathogens  # Adiciona presen√ßa/aus√™ncia de pat√≥genos
}
```

---

#### 3.3 Normaliza√ß√£o e Transforma√ß√£o

**Alinhamento com a Matriz de Treinamento:**

```python
# Ler matriz de treinamento para obter colunas
train_matrix = pd.read_csv('pivoted-virome-organisms-atleast10tpm-species-covid-TCC-pos.csv')

# Obter lista de organismos (features) da matriz de treinamento
feature_columns = [col for col in train_matrix.columns if col not in ['sample_id', 'covid_status']]

# Criar vetor de features do paciente alinhado com a matriz de treinamento
patient_features = pd.DataFrame(index=[0])

for organism in feature_columns:
    # Procurar correspond√™ncia no dicion√°rio de features
    # Pode ser necess√°rio normalizar nomes (remover espa√ßos, etc.)
    tpm_value = features_dict.get(organism, 0)
    patient_features[organism] = tpm_value

# Adicionar features avan√ßadas
for feature_name, feature_value in advanced_features.items():
    patient_features[feature_name] = feature_value

# Aplicar transforma√ß√£o logar√≠tmica (se necess√°rio)
# TPM + 1 para evitar log(0)
patient_features_log = np.log1p(patient_features)

# Salvar vetor de features
patient_features.to_csv('patient_joao_features_vector.csv', index=False)
patient_features_log.to_csv('patient_joao_features_vector_log.csv', index=False)
```

**Justificativa das Transforma√ß√µes:**
- **TPM**: Normaliza por profundidade de sequenciamento e tamanho do genoma
- **Log-transform**: Estabiliza vari√¢ncia e reduz impacto de outliers
- **StandardScaler**: Pode ser aplicado antes do ML para normalizar escala

---

#### 3.4 Valida√ß√£o e Verifica√ß√£o

```python
# Verificar se todas as features da matriz de treinamento est√£o presentes
missing_features = set(feature_columns) - set(patient_features.columns)
if missing_features:
    print(f"Aten√ß√£o: {len(missing_features)} features faltando")
    # Adicionar com valor 0
    for feat in missing_features:
        patient_features[feat] = 0

# Verificar distribui√ß√£o
print("Estat√≠sticas do vetor de features:")
print(patient_features.describe())

# Visualiza√ß√£o
import matplotlib.pyplot as plt

# Top 20 organismos por TPM
top_orgs = patient_features[feature_columns].T.sort_values(by=0, ascending=False).head(20)
plt.figure(figsize=(10, 8))
plt.barh(range(len(top_orgs)), top_orgs[0].values)
plt.yticks(range(len(top_orgs)), top_orgs.index)
plt.xlabel('TPM')
plt.title('Top 20 Organismos - Paciente Jo√£o')
plt.tight_layout()
plt.savefig('patient_features_top20.png')
```

---

### Sa√≠das Finais da Etapa 3

1. **Vetor de Features:**
   - `patient_joao_features_vector.csv`: Features em TPM
   - `patient_joao_features_vector_log.csv`: Features com transforma√ß√£o log

2. **Features Avan√ßadas:**
   - Diversidade alfa, raz√£o v√≠rus/bact√©rias, muta√ß√µes Spike, etc.

3. **Valida√ß√£o:**
   - Verifica√ß√£o de alinhamento com matriz de treinamento
   - Estat√≠sticas descritivas

4. **Visualiza√ß√µes:**
   - Gr√°ficos de distribui√ß√£o de features

---

## Etapa 4: Treinamento e Predi√ß√£o com Machine Learning

### Objetivo
Treinar um modelo supervisionado para predi√ß√£o de COVID-19 com base em dados metatranscript√¥micos e aplicar na amostra do paciente.

### Dados de Entrada

**Matriz de Treinamento:**
- `pivoted-virome-organisms-atleast10tpm-species-covid-TCC-pos.csv`
  - Colunas: organismos (features) + coluna de r√≥tulo (covid_status: True/False)
  - 100 amostras

**Vetor de Features do Paciente:**
- `patient_joao_features_vector.csv` ou `patient_joao_features_vector_log.csv`

---

### Passo a Passo Detalhado

#### 4.1 Explora√ß√£o dos Dados (EDA)

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from xgboost import XGBClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import warnings
warnings.filterwarnings('ignore')

# Ler matriz de treinamento
df = pd.read_csv('pivoted-virome-organisms-atleast10tpm-species-covid-TCC-pos.csv')

# Verificar estrutura
print("Shape:", df.shape)
print("\nPrimeiras linhas:")
print(df.head())

# Verificar balanceamento das classes
print("\nDistribui√ß√£o de classes:")
print(df['covid_status'].value_counts())
print(df['covid_status'].value_counts(normalize=True))

# Visualizar balanceamento
plt.figure(figsize=(8, 5))
df['covid_status'].value_counts().plot(kind='bar')
plt.title('Distribui√ß√£o de Classes')
plt.xlabel('COVID-19 Status')
plt.ylabel('N√∫mero de Amostras')
plt.xticks(rotation=0)
plt.tight_layout()
plt.savefig('class_distribution.png')

# Verificar valores faltantes
print("\nValores faltantes:")
print(df.isnull().sum().sum())

# An√°lise de correla√ß√£o entre features
feature_cols = [col for col in df.columns if col != 'covid_status']
correlation_matrix = df[feature_cols].corr()

plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, cmap='coolwarm', center=0, square=True, linewidths=0.5)
plt.title('Matriz de Correla√ß√£o entre Features')
plt.tight_layout()
plt.savefig('correlation_matrix.png')
```

---

#### 4.2 Pr√©-processamento

```python
# Separar features e target
X = df[feature_cols].copy()
y = df['covid_status'].copy()

# Converter target para bin√°rio (se necess√°rio)
if y.dtype == 'object':
    y = y.map({True: 1, False: 0, 'True': 1, 'False': 0})

# Aplicar transforma√ß√£o logar√≠tmica (se ainda n√£o aplicada)
X_log = np.log1p(X)

# Normaliza√ß√£o (StandardScaler)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_log)
X_scaled = pd.DataFrame(X_scaled, columns=feature_cols)

# Divis√£o treino/teste
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

print(f"Treino: {X_train.shape[0]} amostras")
print(f"Teste: {X_test.shape[0]} amostras")
print(f"Propor√ß√£o de classes no treino: {y_train.value_counts(normalize=True)}")
print(f"Propor√ß√£o de classes no teste: {y_test.value_counts(normalize=True)}")
```

---

#### 4.3 Treinamento de Modelos

**Op√ß√£o 1: Random Forest**

```python
# Random Forest
rf_model = RandomForestClassifier(
    n_estimators=100,
    max_depth=10,
    min_samples_split=5,
    min_samples_leaf=2,
    random_state=42,
    n_jobs=-1
)

rf_model.fit(X_train, y_train)

# Predi√ß√µes
y_pred_rf = rf_model.predict(X_test)
y_pred_proba_rf = rf_model.predict_proba(X_test)[:, 1]

# M√©tricas
print("=== Random Forest ===")
print(classification_report(y_test, y_pred_rf))
print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_rf):.4f}")

# Import√¢ncia das features
feature_importance = pd.DataFrame({
    'feature': feature_cols,
    'importance': rf_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nTop 10 Features Mais Importantes:")
print(feature_importance.head(10))

# Visualizar import√¢ncia
plt.figure(figsize=(10, 8))
top_features = feature_importance.head(20)
plt.barh(range(len(top_features)), top_features['importance'].values)
plt.yticks(range(len(top_features)), top_features['feature'].values)
plt.xlabel('Import√¢ncia')
plt.title('Top 20 Features - Random Forest')
plt.tight_layout()
plt.savefig('feature_importance_rf.png')
```

**Op√ß√£o 2: XGBoost**

```python
# XGBoost
xgb_model = XGBClassifier(
    n_estimators=100,
    max_depth=5,
    learning_rate=0.1,
    random_state=42,
    eval_metric='logloss'
)

xgb_model.fit(X_train, y_train)

# Predi√ß√µes
y_pred_xgb = xgb_model.predict(X_test)
y_pred_proba_xgb = xgb_model.predict_proba(X_test)[:, 1]

# M√©tricas
print("=== XGBoost ===")
print(classification_report(y_test, y_pred_xgb))
print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_xgb):.4f}")

# Import√¢ncia das features
feature_importance_xgb = pd.DataFrame({
    'feature': feature_cols,
    'importance': xgb_model.feature_importances_
}).sort_values('importance', ascending=False)

print("\nTop 10 Features Mais Importantes:")
print(feature_importance_xgb.head(10))
```

**Op√ß√£o 3: Logistic Regression**

```python
# Logistic Regression
lr_model = LogisticRegression(
    max_iter=1000,
    random_state=42,
    C=1.0
)

lr_model.fit(X_train, y_train)

# Predi√ß√µes
y_pred_lr = lr_model.predict(X_test)
y_pred_proba_lr = lr_model.predict_proba(X_test)[:, 1]

# M√©tricas
print("=== Logistic Regression ===")
print(classification_report(y_test, y_pred_lr))
print(f"ROC-AUC: {roc_auc_score(y_test, y_pred_proba_lr):.4f}")

# Coeficientes
coef_df = pd.DataFrame({
    'feature': feature_cols,
    'coefficient': lr_model.coef_[0]
}).sort_values('coefficient', key=abs, ascending=False)

print("\nTop 10 Features por Coeficiente:")
print(coef_df.head(10))
```

---

#### 4.4 Avalia√ß√£o e Sele√ß√£o do Melhor Modelo

```python
# Comparar modelos
models = {
    'Random Forest': (y_pred_rf, y_pred_proba_rf),
    'XGBoost': (y_pred_xgb, y_pred_proba_xgb),
    'Logistic Regression': (y_pred_lr, y_pred_proba_lr)
}

results = []
for name, (y_pred, y_pred_proba) in models.items():
    results.append({
        'Model': name,
        'Accuracy': (y_pred == y_test).mean(),
        'ROC-AUC': roc_auc_score(y_test, y_pred_proba),
        'Precision': classification_report(y_test, y_pred, output_dict=True)['1']['precision'],
        'Recall': classification_report(y_test, y_pred, output_dict=True)['1']['recall'],
        'F1-Score': classification_report(y_test, y_pred, output_dict=True)['1']['f1-score']
    })

results_df = pd.DataFrame(results)
print("\nCompara√ß√£o de Modelos:")
print(results_df)

# Visualizar compara√ß√£o
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# M√©tricas de classifica√ß√£o
metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']
x = np.arange(len(metrics))
width = 0.25

for i, model in enumerate(results_df['Model']):
    values = [results_df.loc[i, m] for m in metrics]
    axes[0].bar(x + i*width, values, width, label=model)

axes[0].set_xlabel('M√©tricas')
axes[0].set_ylabel('Score')
axes[0].set_title('Compara√ß√£o de M√©tricas de Classifica√ß√£o')
axes[0].set_xticks(x + width)
axes[0].set_xticklabels(metrics)
axes[0].legend()
axes[0].grid(axis='y', alpha=0.3)

# ROC-AUC
axes[1].bar(results_df['Model'], results_df['ROC-AUC'])
axes[1].set_ylabel('ROC-AUC Score')
axes[1].set_title('Compara√ß√£o de ROC-AUC')
axes[1].grid(axis='y', alpha=0.3)

plt.tight_layout()
plt.savefig('model_comparison.png')

# Selecionar melhor modelo (baseado em ROC-AUC)
best_model_name = results_df.loc[results_df['ROC-AUC'].idxmax(), 'Model']
print(f"\nMelhor modelo: {best_model_name}")

# Salvar melhor modelo
if best_model_name == 'Random Forest':
    best_model = rf_model
elif best_model_name == 'XGBoost':
    best_model = xgb_model
else:
    best_model = lr_model

import joblib
joblib.dump(best_model, 'best_model.pkl')
joblib.dump(scaler, 'scaler.pkl')
```

**Visualiza√ß√£o de M√©tricas:**

```python
# Matriz de Confus√£o
from sklearn.metrics import ConfusionMatrixDisplay

fig, axes = plt.subplots(1, 3, figsize=(15, 4))

for idx, (name, (y_pred, _)) in enumerate(models.items()):
    ConfusionMatrixDisplay.from_predictions(y_test, y_pred, ax=axes[idx])
    axes[idx].set_title(f'{name} - Matriz de Confus√£o')

plt.tight_layout()
plt.savefig('confusion_matrices.png')

# Curvas ROC
fig, ax = plt.subplots(figsize=(8, 6))

for name, (_, y_pred_proba) in models.items():
    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
    auc = roc_auc_score(y_test, y_pred_proba)
    ax.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})')

ax.plot([0, 1], [0, 1], 'k--', label='Random')
ax.set_xlabel('Taxa de Falsos Positivos')
ax.set_ylabel('Taxa de Verdadeiros Positivos')
ax.set_title('Curvas ROC')
ax.legend()
ax.grid(alpha=0.3)
plt.tight_layout()
plt.savefig('roc_curves.png')
```

---

#### 4.5 Predi√ß√£o da Amostra do Paciente

```python
# Ler vetor de features do paciente
patient_features = pd.read_csv('patient_joao_features_vector.csv')

# Garantir mesma ordem de colunas
patient_X = patient_features[feature_cols].copy()

# Aplicar mesma transforma√ß√£o
patient_X_log = np.log1p(patient_X)
patient_X_scaled = scaler.transform(patient_X_log)
patient_X_scaled = pd.DataFrame(patient_X_scaled, columns=feature_cols)

# Predi√ß√£o
patient_pred = best_model.predict(patient_X_scaled)[0]
patient_pred_proba = best_model.predict_proba(patient_X_scaled)[0]

print("=== Predi√ß√£o para Paciente Jo√£o ===")
print(f"Predi√ß√£o: {'POSITIVO para COVID-19' if patient_pred == 1 else 'NEGATIVO para COVID-19'}")
print(f"Probabilidade de COVID-19: {patient_pred_proba[1]:.4f} ({patient_pred_proba[1]*100:.2f}%)")
print(f"Probabilidade de N√ÉO COVID-19: {patient_pred_proba[0]:.4f} ({patient_pred_proba[0]*100:.2f}%)")

# Salvar resultado
result = pd.DataFrame({
    'patient': ['Jo√£o'],
    'prediction': [patient_pred],
    'probability_covid': [patient_pred_proba[1]],
    'probability_no_covid': [patient_pred_proba[0]]
})
result.to_csv('patient_joao_prediction.csv', index=False)
```

**Interpreta√ß√£o com SHAP (opcional, mas recomendado):**

```python
# Instalar: pip install shap
import shap

# Criar explainer
explainer = shap.TreeExplainer(best_model)
shap_values = explainer.shap_values(patient_X_scaled)

# Visualizar import√¢ncia para esta predi√ß√£o espec√≠fica
shap.summary_plot(shap_values, patient_X_scaled, plot_type="bar", show=False)
plt.savefig('shap_summary.png', bbox_inches='tight')

# Waterfall plot para a predi√ß√£o do paciente
shap.waterfall_plot(explainer(patient_X_scaled)[0], show=False)
plt.savefig('shap_waterfall_patient.png', bbox_inches='tight')
```

---

### Sa√≠das Finais da Etapa 4

1. **Modelo Treinado:**
   - `best_model.pkl`: Modelo salvo
   - `scaler.pkl`: Scaler salvo

2. **Avalia√ß√£o:**
   - Relat√≥rio de classifica√ß√£o (precision, recall, F1-score)
   - Matriz de confus√£o
   - Curva ROC
   - Compara√ß√£o de modelos

3. **Predi√ß√£o do Paciente:**
   - `patient_joao_prediction.csv`: Resultado da predi√ß√£o
   - Probabilidade de COVID-19

4. **Interpretabilidade:**
   - Import√¢ncia de features
   - Gr√°ficos SHAP (se aplicado)

5. **Visualiza√ß√µes:**
   - Distribui√ß√£o de classes
   - Matriz de correla√ß√£o
   - Import√¢ncia de features
   - Matriz de confus√£o
   - Curvas ROC

---

## Recursos e Refer√™ncias

### Bancos de Dados e Refer√™ncias

1. **Genoma de Refer√™ncia SARS-CoV-2:**
   - https://www.ncbi.nlm.nih.gov/nuccore/NC_045512.2
   - Genoma Wuhan (padr√£o)

2. **Genotipagem SARS-CoV-2:**
   - https://pangolin.cog-uk.io/
   - Ferramenta web e linha de comando

3. **An√°lise de Resist√™ncia a Antibi√≥ticos:**
   - https://card.mcmaster.ca/analyze/rgi
   - Comprehensive Antibiotic Resistance Database (CARD)

4. **Genoma Humano (HG38):**
   - https://hgdownload.soe.ucsc.edu/goldenPath/hg38/bigZips/
   - Para remo√ß√£o de reads do hospedeiro

5. **Bancos Kraken2 Pr√©-constru√≠dos:**
   - https://genome-idx.s3.amazonaws.com/kraken/
   - Bancos de v√≠rus e bact√©rias

### Ferramentas Principais

| Ferramenta | Uso | Instala√ß√£o |
|-----------|-----|------------|
| FastQC | Controle de qualidade | `conda install -c bioconda fastqc` |
| MultiQC | Consolida√ß√£o de relat√≥rios | `conda install -c bioconda multiqc` |
| Trimmomatic | Trimming de reads | `conda install -c bioconda trimmomatic` |
| fastp | Trimming r√°pido | `conda install -c bioconda fastp` |
| Bowtie2 | Alinhamento | `conda install -c bioconda bowtie2` |
| BWA | Alinhamento | `conda install -c bioconda bwa` |
| Kraken2 | Classifica√ß√£o taxon√¥mica | `conda install -c bioconda kraken2` |
| Bracken | Estimativa de abund√¢ncia | `conda install -c bioconda bracken` |
| samtools | Manipula√ß√£o de BAM | `conda install -c bioconda samtools` |
| bcftools | Chamada de variantes | `conda install -c bioconda bcftools` |
| FreeBayes | Chamada de variantes | `conda install -c bioconda freebayes` |
| SnpEff | Anota√ß√£o de variantes | `conda install -c bioconda snpeff` |
| Pangolin | Determina√ß√£o de linhagem | `pip install pangolin` |
| Krona | Visualiza√ß√£o taxon√¥mica | `conda install -c bioconda krona` |

### Bibliotecas Python

```bash
pip install pandas numpy matplotlib seaborn scikit-learn xgboost shap scipy
```

### Estrutura de Arquivos Recomendada

```
tcc-metatranscriptomica/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ patient_joao_VIROMA_S21_R1_001.fastq.gz
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ patient_joao_VIROMA_S21_R2_001.fastq.gz
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ patient_joao_R1_trimmed.fastq.gz
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ patient_joao_R2_trimmed.fastq.gz
‚îÇ   ‚îú‚îÄ‚îÄ references/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ NC_045512.2.fasta
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hg38.fa
‚îÇ   ‚îî‚îÄ‚îÄ training/
‚îÇ       ‚îî‚îÄ‚îÄ pivoted-virome-organisms-atleast10tpm-species-covid-TCC-pos.csv
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_metatranscriptomica_pipeline.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 02_variant_calling_pipeline.ipynb
‚îÇ   ‚îú‚îÄ‚îÄ 03_feature_engineering.ipynb
‚îÇ   ‚îî‚îÄ‚îÄ 04_ml_training_prediction.ipynb
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ qc_reports/
‚îÇ   ‚îú‚îÄ‚îÄ kraken2_reports/
‚îÇ   ‚îú‚îÄ‚îÄ variants/
‚îÇ   ‚îú‚îÄ‚îÄ features/
‚îÇ   ‚îî‚îÄ‚îÄ ml_results/
‚îî‚îÄ‚îÄ guia-execucao-tcc.md
```

---

## Checklist Final

Antes da entrega, verificar:

- [ ] Todos os notebooks executam sem erros
- [ ] Relat√≥rios de qualidade gerados e interpretados
- [ ] Classifica√ß√£o taxon√¥mica completa (Kraken2/Bracken)
- [ ] Variantes identificadas e anotadas
- [ ] Linhagem determinada (Pangolin)
- [ ] Vetor de features alinhado com matriz de treinamento
- [ ] Modelo treinado e avaliado com m√©tricas adequadas
- [ ] Predi√ß√£o do paciente realizada
- [ ] Todas as quest√µes da apresenta√ß√£o respondidas
- [ ] Visualiza√ß√µes claras e informativas
- [ ] C√≥digo comentado e documentado

---

**Boa sorte com o TCC! üß¨üî¨ü§ñ**

